{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 信息与内容安全作业1：虚假人脸检测实验\n",
    "题目：给定一个人脸数据集，其中包含1999张真实人脸， 1999张虚假人脸。将其中500张真实人脸和500张虚假人脸作为训练集，其余作为测试集。\n",
    "根据给定数据集训练训练一个虚假人脸检测器，该检测器本质就是一个二分类分类器。要求利用Pytorch框架任意设计一种神经网络模型进行分类，分类准确率越高越好\n",
    "\n",
    "Author：191801001-蒋凯安\n",
    "# Import Some Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.functional import F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "\n",
    "myseed = 42069  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup Hyper-parameters\n",
    "`config`包含模型超参数和模型存放路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/detect_fake_faces', flush_secs=60)\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")          \n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = False                   \n",
    "\n",
    "# TODO: 炼丹\n",
    "config = {\n",
    "    'n_epochs': 200,                 # maximum number of epochs\n",
    "    'batch_size': 32,                # mini-batch size for dataloader\n",
    "    'lr':1e-3,\n",
    "    'lr_decay':0.95,\n",
    "    'early_stop': 20,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset\n",
    "设置3类dataset:\n",
    "* `train`: for 训练（调整网络参数）\n",
    "* `dev`: for 验证（训练时可以根据验证集上的表现提前终止训练，或调整超参数）\n",
    "* `test`: for 测试（训练结束后测试网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RealOrFakeFaceDateset(Dataset):\n",
    "    def __init__(self, type, transform=None, target_transform=None):\n",
    "        assert (type == \"Real\") or (type == \"Fake\")\n",
    "        # label=0表示Real人脸，label=1表示Fake人脸\n",
    "        if type == \"Real\":\n",
    "            self.label = 0  \n",
    "            self.img_dir = \"data/0_real\"\n",
    "        else:\n",
    "            self.label = 1\n",
    "            self.img_dir = \"data/1_fake\"\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        files = os.listdir(self.img_dir)\n",
    "        return len(files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \"{:0>4d}.png\".format(idx))\n",
    "        image = read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, self.label\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "real_face_datasets = RealOrFakeFaceDateset(type=\"Real\", transform=transform)\n",
    "fake_face_datasets = RealOrFakeFaceDateset(type=\"Fake\", transform=transform)\n",
    "# 将真实和虚假人脸图像，按固定数据，分为 train, dev,test真实/虚假数据集\n",
    "assert len(real_face_datasets) == len(fake_face_datasets) == 1999\n",
    "# int(500*(1-0.8))=99，你信吗？\n",
    "tran_size, dev_size, test_size = int(500*0.8), int(500-500*0.8), len(real_face_datasets) - 500\n",
    "real_train_set, real_dev_set, real_test_set = random_split(real_face_datasets, \\\n",
    "    (tran_size, dev_size, test_size))\n",
    "fake_train_set, fake_dev_set, fake_test_set = random_split(fake_face_datasets, \\\n",
    "    (tran_size, dev_size, test_size))\n",
    "\n",
    "# 连接数据集，组成train, dev, test数据集\n",
    "train_dataset = ConcatDataset((real_train_set, fake_train_set))\n",
    "dev_dataset = ConcatDataset((real_dev_set, fake_dev_set))\n",
    "test_dataset = ConcatDataset((real_test_set, fake_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_set) = 800 \n",
      "len(dev_set) = 200 \n",
      "len(test_set) = 2998\n",
      "Shape of element in train_set: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# print(dir(train_dataset.datasets))\n",
    "print(f\"len(train_set) = {len(train_dataset)} \\nlen(dev_set) = {len(dev_dataset)} \\nlen(test_set) = {len(test_dataset)}\")\n",
    "print(\"Shape of element in train_set:\", train_dataset[0][0].shape) # 第1个样本的img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "dev_set = DataLoader(dev_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_set = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "dataiter = iter(train_set)\n",
    "faces, labels = next(dataiter)\n",
    "faces_grid = make_grid(faces)\n",
    "writer.add_image('A mini-batch of faces', faces_grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Training Dataset with embedding\n",
    "二分类问题，效果好像并不好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = [\"Real\",\"Fake\"]\n",
    "# for x, y in train_set:\n",
    "#     faces = torch.vstack((faces, x))\n",
    "#     labels = torch.hstack((labels, y))\n",
    "    \n",
    "# print(\"Shape of faces:\", faces.shape)\n",
    "# print(\"Shape of labels:\", labels.shape)\n",
    "# # get the class labels for each image\n",
    "# class_labels = [classes[label] for label in labels]\n",
    "\n",
    "# # log embeddings\n",
    "# features = faces.view(-1, 3 * 224 * 224)\n",
    "# writer.add_embedding(features,\n",
    "#                     metadata=class_labels,\n",
    "#                     label_img=faces.mean(dim=1, keepdim=True))\n",
    "# writer.flush()\n",
    "# del faces, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model: Modified Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "        self.model = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/peced/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "# 模型可视化\n",
    "writer.add_graph(net, dataiter.next()[0].to(device))\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loss && Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=config[\"lr\"])\n",
    "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=config['lr_decay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train/Dev/Test\n",
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_set, dev_set, net):\n",
    "    n_epochs = config[\"n_epochs\"]\n",
    "    min_loss = 1000\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    train_total_loss = 0\n",
    "\n",
    "    while epoch < n_epochs:\n",
    "        net.train()\n",
    "        for batch_idx, (x, y) in enumerate(train_set):\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = net(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            train_total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "            \n",
    "        #每个epoch进行一次Validate\n",
    "        dev_loss, dev_acc = dev(dev_set, net, device) \n",
    "        if dev_loss < min_loss:\n",
    "            # 模型进步\n",
    "            min_loss = dev_loss\n",
    "            early_stop_cnt = 0          \n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "        # 展示\n",
    "        print('epoch = {:>3d}, dev_loss = {:>.4f} dev_acc = {:.2%}'.format(epoch + 1, dev_loss, dev_acc))\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                {'Training':train_total_loss/len(train_set), 'Validation':dev_loss},\n",
    "                epoch)\n",
    "        train_total_loss = 0\n",
    "\n",
    "        epoch += 1\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # 连续\"config['early_stop']\"没进步，则强制停止训练\n",
    "            break\n",
    "            \n",
    "    writer.flush()\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dev(dev_set, net, device):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for x, y in dev_set:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            total_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() #item()可将tensor数转化为一般数\n",
    "    v_loss = total_loss / len(dev_set)\n",
    "    v_accuracy = correct / len(dev_set.dataset) \n",
    "    return v_loss, v_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(test_set, net, device):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for x, y in test_set:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            total_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() #item()可将tensor数转化为一般数\n",
    "    t_loss = total_loss / len(test_set)\n",
    "    t_accuracy = correct / len(test_set.dataset) \n",
    "    return t_loss, t_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =   1, dev_loss = 1.2054 dev_acc = 76.00%\n",
      "epoch =   2, dev_loss = 1.0251 dev_acc = 76.50%\n",
      "epoch =   3, dev_loss = 0.2297 dev_acc = 92.50%\n",
      "epoch =   4, dev_loss = 1.8180 dev_acc = 59.50%\n",
      "epoch =   5, dev_loss = 0.5837 dev_acc = 78.50%\n",
      "epoch =   6, dev_loss = 0.0578 dev_acc = 97.00%\n",
      "epoch =   7, dev_loss = 0.0402 dev_acc = 97.50%\n",
      "epoch =   8, dev_loss = 0.0436 dev_acc = 98.50%\n",
      "epoch =   9, dev_loss = 0.1069 dev_acc = 95.00%\n",
      "epoch =  10, dev_loss = 0.0416 dev_acc = 98.50%\n",
      "epoch =  11, dev_loss = 0.0341 dev_acc = 99.50%\n",
      "epoch =  12, dev_loss = 0.0030 dev_acc = 100.00%\n",
      "epoch =  13, dev_loss = 0.0020 dev_acc = 100.00%\n",
      "epoch =  14, dev_loss = 0.0005 dev_acc = 100.00%\n",
      "epoch =  15, dev_loss = 0.0002 dev_acc = 100.00%\n",
      "epoch =  16, dev_loss = 0.0002 dev_acc = 100.00%\n",
      "epoch =  17, dev_loss = 0.0002 dev_acc = 100.00%\n",
      "epoch =  18, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  19, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  20, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  21, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  22, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  23, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  24, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  25, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  26, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  27, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  28, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  29, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  30, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  31, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  32, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  33, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  34, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  35, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  36, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  37, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  38, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  39, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  40, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  41, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  42, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  43, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  44, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  45, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  46, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  47, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  48, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  49, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  50, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  51, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  52, dev_loss = 0.0003 dev_acc = 100.00%\n",
      "epoch =  53, dev_loss = 0.0003 dev_acc = 100.00%\n",
      "epoch =  54, dev_loss = 0.0002 dev_acc = 100.00%\n",
      "epoch =  55, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  56, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  57, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  58, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  59, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  60, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  61, dev_loss = 0.0001 dev_acc = 100.00%\n",
      "epoch =  62, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  63, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  64, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  65, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  66, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  67, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  68, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  69, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  70, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  71, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  72, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  73, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  74, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  75, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  76, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  77, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  78, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  79, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  80, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  81, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  82, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  83, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  84, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  85, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  86, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  87, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  88, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  89, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  90, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  91, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  92, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  93, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  94, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  95, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  96, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  97, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  98, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch =  99, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 100, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 101, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 102, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 103, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 104, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 105, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 106, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 107, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 108, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 109, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 110, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 111, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 112, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 113, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 114, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 115, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 116, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 117, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 118, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 119, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 120, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 121, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 122, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 123, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 124, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 125, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 126, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 127, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 128, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 129, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 130, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 131, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 132, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 133, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 134, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 135, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 136, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 137, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 138, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 139, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 140, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 141, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 142, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 143, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 144, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 145, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 146, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 147, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 148, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 149, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 150, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 151, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 152, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 153, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 154, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 155, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 156, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 157, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 158, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 159, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 160, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 161, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 162, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 163, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 164, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 165, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 166, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 167, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 168, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 169, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 170, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 171, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 172, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 173, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 174, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 175, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 176, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 177, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 178, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 179, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 180, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 181, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 182, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 183, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 184, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 185, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 186, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 187, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 188, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 189, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 190, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 191, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 192, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 193, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 194, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 195, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 196, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 197, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 198, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 199, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "epoch = 200, dev_loss = 0.0000 dev_acc = 100.00%\n",
      "Finished training after 200 epochs\n",
      "\n",
      "Processing testing...\n",
      "test_loss = 6.895284376003503e-07 test_acc = 1.0\n"
     ]
    }
   ],
   "source": [
    "train(train_set, dev_set, net)\n",
    "test_loss, test_acc = test(test_set, net, device)\n",
    "print(f\"\\nProcessing testing...\\ntest_loss = {test_loss} test_acc = {test_acc}\")\n",
    "torch.save(net.state_dict(), config[\"save.pth\"])\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "507dc60e1f06788952fdb36d8c2396ff6b3e6bf8b7cb536e77c2ccfb244ccc60"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
